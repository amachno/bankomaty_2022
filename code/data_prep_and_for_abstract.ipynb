{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bankomaty do wyrzucenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_to_remove = [79, 80, 81]\n",
    "# adding columns for which there are NaNs in SARIMA\n",
    "numbers_to_remove += [1, 4, 15, 16, 17, 18, 26, 28, 29, 40, 42, 47, 54, 59, 67, 71, 77]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numbers_to_remove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import RF & XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from utils import ends_with_number\n",
    "\n",
    "# Define the folder where the CSV files are located\n",
    "folder_path = r'D:\\AGH\\bankomaty_2022\\data\\redatyprognoz'\n",
    "\n",
    "# Use glob to find all CSV files in the folder\n",
    "file_pattern = folder_path + r'\\prognozy_W_*.csv'\n",
    "file_list = glob.glob(file_pattern)\n",
    "\n",
    "# Create an empty list to hold the DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop over each file and read it into a DataFrame\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    period_id = df['date'].min()\n",
    "    df['periodID'] = period_id\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "xgb_raw_df = pd.concat(df_list)\n",
    "\n",
    "# Print the resulting data frame\n",
    "xgb_raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of column names to keep\n",
    "columns_to_keep = [column for column in xgb_raw_df.columns if not ends_with_number(column, ['{:02d}'.format(num) for num in numbers_to_remove])]\n",
    "\n",
    "# Remove the columns from the data frame\n",
    "xgb_raw_df = xgb_raw_df[columns_to_keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE averages for XGB before and after COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where date equals 'MAPE'\n",
    "mape_df = xgb_raw_df[xgb_raw_df['date'] == 'MAPE']\n",
    "mape_df = mape_df.drop('date', axis=1)\n",
    "\n",
    "mape_df['mean_except_periodID'] = mape_df.drop('periodID', axis=1).mean(axis=1)\n",
    "mape_df = mape_df.rename(columns={'mean_except_periodID': 'mape'})\n",
    "\n",
    "mape_df = mape_df[['periodID', 'mape']]\n",
    "\n",
    "mape_df_sorted = mape_df.sort_values('periodID')\n",
    "mape_first_5_avg = mape_df_sorted.iloc[:5]['mape'].mean()\n",
    "mape_last_5_avg = mape_df_sorted.iloc[-5:]['mape'].mean()\n",
    "\n",
    "print(mape_first_5_avg)\n",
    "print(mape_last_5_avg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMAPE averages for XGB before and after COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where date equals 'MAPE'\n",
    "mape_df = xgb_raw_df[xgb_raw_df['date'] == 'SMAPE']\n",
    "mape_df = mape_df.drop('date', axis=1)\n",
    "\n",
    "mape_df['mean_except_periodID'] = mape_df.drop('periodID', axis=1).mean(axis=1)\n",
    "mape_df = mape_df.rename(columns={'mean_except_periodID': 'smape'})\n",
    "\n",
    "mape_df = mape_df[['periodID', 'smape']]\n",
    "\n",
    "mape_df_sorted = mape_df.sort_values('periodID')\n",
    "smape_first_5_avg = mape_df_sorted.iloc[:5]['smape'].mean()\n",
    "smape_last_5_avg = mape_df_sorted.iloc[-5:]['smape'].mean()\n",
    "\n",
    "print(smape_first_5_avg)\n",
    "print(smape_last_5_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE & SMAPE averages for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb_raw_df[xgb_raw_df['date'] == 'MAPE'].mean().mean())\n",
    "print(xgb_raw_df[xgb_raw_df['date'] == 'SMAPE'].mean().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder where the CSV files are located\n",
    "folder_path = r'D:\\AGH\\bankomaty_2022\\data\\redatyprognoz'\n",
    "\n",
    "# Use glob to find all CSV files in the folder\n",
    "file_pattern = folder_path + r'\\prognozy_rf_W_*.csv'\n",
    "file_list = glob.glob(file_pattern)\n",
    "\n",
    "# Create an empty list to hold the DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop over each file and read it into a DataFrame\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    period_id = df['date'].min()\n",
    "    df['periodID'] = period_id\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "rf_raw_df = pd.concat(df_list)\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "rf_raw_df  = pd.concat(df_list)\n",
    "\n",
    "rf_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of column names to keep\n",
    "columns_to_keep = [column for column in rf_raw_df.columns if not ends_with_number(column, numbers_to_remove)]\n",
    "\n",
    "# Remove the columns from the data frame\n",
    "rf_raw_df = rf_raw_df[columns_to_keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE averages for RF before and after COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where date equals 'MAPE'\n",
    "mape_df = rf_raw_df[rf_raw_df['date'] == 'MAPE']\n",
    "mape_df = mape_df.drop('date', axis=1)\n",
    "\n",
    "mape_df['mean_except_periodID'] = mape_df.drop('periodID', axis=1).mean(axis=1)\n",
    "mape_df = mape_df.rename(columns={'mean_except_periodID': 'mape'})\n",
    "\n",
    "mape_df = mape_df[['periodID', 'mape']]\n",
    "\n",
    "mape_df_sorted = mape_df.sort_values('periodID')\n",
    "mape_first_5_avg = mape_df_sorted.iloc[:5]['mape'].mean()\n",
    "mape_last_5_avg = mape_df_sorted.iloc[-5:]['mape'].mean()\n",
    "\n",
    "print(mape_first_5_avg)\n",
    "print(mape_last_5_avg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMAPE averages for RF before and after COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where date equals 'MAPE'\n",
    "mape_df = rf_raw_df[rf_raw_df['date'] == 'SMAPE']\n",
    "mape_df = mape_df.drop('date', axis=1)\n",
    "\n",
    "mape_df['mean_except_periodID'] = mape_df.drop('periodID', axis=1).mean(axis=1)\n",
    "mape_df = mape_df.rename(columns={'mean_except_periodID': 'smape'})\n",
    "\n",
    "mape_df = mape_df[['periodID', 'smape']]\n",
    "\n",
    "mape_df_sorted = mape_df.sort_values('periodID')\n",
    "smape_first_5_avg = mape_df_sorted.iloc[:5]['smape'].mean()\n",
    "smape_last_5_avg = mape_df_sorted.iloc[-5:]['smape'].mean()\n",
    "\n",
    "print(smape_first_5_avg)\n",
    "print(smape_last_5_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE & SMAPE averages for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_raw_df[rf_raw_df['date'] == 'MAPE'].mean().mean())\n",
    "print(rf_raw_df[rf_raw_df['date'] == 'SMAPE'].mean().mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Define the directory where the Excel files are stored\n",
    "directory = \"D:/AGH/bankomaty_2022/data/Wielkość wypłat\"\n",
    "\n",
    "# Get a list of all Excel files in the directory\n",
    "excel_files = [f for f in os.listdir(directory) if f.endswith(\".xlsx\")]\n",
    "\n",
    "# Create an empty list to store the data frames\n",
    "data_frames = []\n",
    "\n",
    "# Loop through each Excel file and load the \"prediction errors\" sheet\n",
    "for i, excel_file in enumerate(excel_files):\n",
    "    file_path = os.path.join(directory, excel_file)\n",
    "    xl = pd.ExcelFile(file_path)\n",
    "    sheet_name = \"prediction errors\"\n",
    "    df = xl.parse(sheet_name)\n",
    "    period_id = os.path.splitext(excel_file)[0]\n",
    "    df['periodID'] = period_id\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Combine all data frames into a single data frame\n",
    "sarima_raw_df = pd.concat(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of column names to keep\n",
    "columns_to_keep = [column for column in sarima_raw_df.columns if not ends_with_number(column, ['{:02d}'.format(num) for num in numbers_to_remove])]\n",
    "\n",
    "# Remove the columns from the data frame\n",
    "sarima_raw_df = sarima_raw_df[columns_to_keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE averages for SARIMA before and after COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where date equals 'MAPE'\n",
    "mape_df = sarima_raw_df[sarima_raw_df['name'] == 'MAPE']\n",
    "mape_df = mape_df.drop('name', axis=1)\n",
    "\n",
    "mape_df['mean_except_periodID'] = mape_df.drop('periodID', axis=1).mean(axis=1)\n",
    "mape_df = mape_df.rename(columns={'mean_except_periodID': 'mape'})\n",
    "\n",
    "mape_df = mape_df[['periodID', 'mape']]\n",
    "\n",
    "mape_df_sorted = mape_df.sort_values('periodID')\n",
    "mape_first_5_avg = mape_df_sorted.iloc[:5]['mape'].mean()\n",
    "mape_last_5_avg = mape_df_sorted.iloc[-5:]['mape'].mean()\n",
    "\n",
    "print(mape_first_5_avg)\n",
    "print(mape_last_5_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMAPE averages for SARIMA before and after COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where date equals 'MAPE'\n",
    "mape_df = sarima_raw_df[sarima_raw_df['name'] == 'SMAPE']\n",
    "mape_df = mape_df.drop('name', axis=1)\n",
    "\n",
    "mape_df['mean_except_periodID'] = mape_df.drop('periodID', axis=1).mean(axis=1)\n",
    "mape_df = mape_df.rename(columns={'mean_except_periodID': 'mape'})\n",
    "\n",
    "mape_df = mape_df[['periodID', 'mape']]\n",
    "\n",
    "mape_df_sorted = mape_df.sort_values('periodID')\n",
    "smape_first_5_avg = mape_df_sorted.iloc[:5]['mape'].mean()\n",
    "smape_last_5_avg = mape_df_sorted.iloc[-5:]['mape'].mean()\n",
    "\n",
    "print(smape_first_5_avg)\n",
    "print(smape_last_5_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE & SMAPE averages for SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sarima_raw_df[sarima_raw_df['name'] == 'MAPE'].mean().mean())\n",
    "print(sarima_raw_df[sarima_raw_df['name'] == 'SMAPE'].mean().mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path of the Excel file\n",
    "file_path = r'D:\\AGH\\bankomaty_2022\\data\\replaced 17-12-2022.xlsx'\n",
    "\n",
    "# Read all sheets with names ending in \"_errors\" into a list of data frames\n",
    "df_list = []\n",
    "xl = pd.ExcelFile(file_path)\n",
    "for sheet_name in xl.sheet_names:\n",
    "    if sheet_name.endswith(\"_errors\"):\n",
    "        df = xl.parse(sheet_name)\n",
    "        period_id = sheet_name[:-7]\n",
    "        day, month, year = period_id.split(\"_\")\n",
    "        new_period_id = f\"{year}_{month}_{day}\"\n",
    "        df['periodID'] = new_period_id\n",
    "        df_list.append(df)\n",
    "\n",
    "# Concatenate the data frames into a single data frame\n",
    "bayes_raw_df = pd.concat(df_list)\n",
    "\n",
    "# Rename the \"Unnamed\" column to \"name\"\n",
    "bayes_raw_df = bayes_raw_df.rename(columns={\"Unnamed: 0\": \"name\"})\n",
    "\n",
    "# Remove columns with names starting with 'ATM_N_'\n",
    "bayes_raw_df = bayes_raw_df.loc[:, ~bayes_raw_df.columns.str.startswith('ATM_N_')]\n",
    "\n",
    "# Print the resulting data frame\n",
    "bayes_raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of column names to keep\n",
    "columns_to_keep = [column for column in bayes_raw_df.columns if not ends_with_number(column, ['{:02d}'.format(num) for num in numbers_to_remove])]\n",
    "\n",
    "# Remove the columns from the data frame\n",
    "bayes_raw_df = bayes_raw_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_raw_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE averages for BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where date equals 'MAPE'\n",
    "mape_df = bayes_raw_df[bayes_raw_df['name'] == 'MAPE']\n",
    "mape_df = mape_df.drop('name', axis=1)\n",
    "\n",
    "mape_df['mean_except_periodID'] = mape_df.drop('periodID', axis=1).mean(axis=1)\n",
    "mape_df = mape_df.rename(columns={'mean_except_periodID': 'mape'})\n",
    "\n",
    "mape_df = mape_df[['periodID', 'mape']]\n",
    "\n",
    "mape_df_sorted = mape_df.sort_values('periodID')\n",
    "mape_first_5_avg = mape_df_sorted.iloc[:5]['mape'].mean()\n",
    "mape_last_5_avg = mape_df_sorted.iloc[-5:]['mape'].mean()\n",
    "\n",
    "print(mape_first_5_avg)\n",
    "print(mape_last_5_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMAPE averages for BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where date equals 'MAPE'\n",
    "mape_df = bayes_raw_df[bayes_raw_df['name'] == 'SMAPE']\n",
    "mape_df = mape_df.drop('name', axis=1)\n",
    "\n",
    "mape_df['mean_except_periodID'] = mape_df.drop('periodID', axis=1).mean(axis=1)\n",
    "mape_df = mape_df.rename(columns={'mean_except_periodID': 'mape'})\n",
    "\n",
    "mape_df = mape_df[['periodID', 'mape']]\n",
    "\n",
    "mape_df_sorted = mape_df.sort_values('periodID')\n",
    "smape_first_5_avg = mape_df_sorted.iloc[:5]['mape'].mean()\n",
    "smape_last_5_avg = mape_df_sorted.iloc[-5:]['mape'].mean()\n",
    "\n",
    "print(smape_first_5_avg)\n",
    "print(smape_last_5_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_raw_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE & SMAPE averages for BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bayes_raw_df.drop('periodID', axis=1).mean(axis=1)[bayes_raw_df['name'] == 'MAPE'].mean().mean())\n",
    "print(bayes_raw_df.drop('periodID', axis=1).mean(axis=1)[bayes_raw_df['name'] == 'SMAPE'].mean().mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rankings per period - MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import change_id \n",
    "from utils import filter_and_remove\n",
    "\n",
    "measure = 'MAPE'\n",
    "\n",
    "xgb_df = xgb_raw_df.rename(columns={'date': 'name'})\n",
    "rf_df = rf_raw_df.rename(columns={'date': 'name'})\n",
    "\n",
    "xgb_df = xgb_df.drop(xgb_df.filter(regex='^pred_W').columns, axis=1)\n",
    "rf_df = rf_df.drop(rf_df.filter(regex='^pred_W').columns, axis=1)\n",
    "\n",
    "xgb_df = change_id(xgb_df)\n",
    "rf_df = change_id(rf_df)\n",
    "sarima_df = change_id(sarima_raw_df)\n",
    "bayes_df = change_id(bayes_raw_df)\n",
    "\n",
    "\n",
    "xgb_df = filter_and_remove(xgb_df, measure)\n",
    "rf_df = filter_and_remove(rf_df, measure)\n",
    "sarima_df = filter_and_remove(sarima_df, measure)\n",
    "bayes_df = filter_and_remove(bayes_df, measure)\n",
    "\n",
    "xgb_df['model'] = 'xgb'\n",
    "rf_df['model'] = 'rf'\n",
    "sarima_df['model'] = 'sarima'\n",
    "bayes_df['model'] = 'bayes'\n",
    "\n",
    "xgb_df.loc[:, xgb_df.columns.str.startswith('ATM_W')] *= 100\n",
    "rf_df.loc[:, rf_df.columns.str.startswith('ATM_W')] *= 100\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary to map old values to new values\n",
    "period_dict = {1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7:8, 8: 9, 9: 10}\n",
    "\n",
    "# replace the old values with the new values in the \"periodID\" column\n",
    "bayes_df['periodID'] = bayes_df['periodID'].map(period_dict).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mape = pd.concat([xgb_df, sarima_df, bayes_df], ignore_index=True)\n",
    "df_mape = df_mape.melt(id_vars=['periodID', 'model'], var_name='ATM', value_name=measure)\n",
    "df_mape['rank'] = df_mape.groupby(['periodID', 'ATM'])[measure].rank(method='min')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE ranking total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# count how many times each model has each ranking\n",
    "df_mape = df_mape[df_mape['model'] != 'rf']\n",
    "counts = df_mape.groupby(['model', 'rank']).size().reset_index(name='count')\n",
    "\n",
    "# pivot the counts dataframe to a wider format\n",
    "pivoted_counts = counts.pivot(index='model', columns='rank', values='count')\n",
    "pivoted_counts.columns = [f'rank_{col}' for col in pivoted_counts.columns]\n",
    "pivoted_counts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE ranking before COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe for periodID <= 5\n",
    "df_mape_filtered = df_mape[df_mape['periodID'] <= 5]\n",
    "df_mape_filtered = df_mape_filtered[df_mape_filtered['model'] != 'rf']\n",
    "\n",
    "# group and count the data\n",
    "counts = df_mape_filtered.groupby(['model', 'rank']).size().reset_index(name='count')\n",
    "\n",
    "# pivot the counts dataframe to a wider format\n",
    "pivoted_counts = counts.pivot(index='model', columns='rank', values='count')\n",
    "pivoted_counts.columns = [f'rank_{col}' for col in pivoted_counts.columns]\n",
    "pivoted_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE ranking after COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe for periodID > 5\n",
    "df_mape_filtered = df_mape[df_mape['periodID'] > 5]\n",
    "df_mape_filtered = df_mape_filtered[df_mape_filtered['model'] != 'rf']\n",
    "\n",
    "# group and count the data\n",
    "counts = df_mape_filtered.groupby(['model', 'rank']).size().reset_index(name='count')\n",
    "\n",
    "# pivot the counts dataframe to a wider format\n",
    "pivoted_counts = counts.pivot(index='model', columns='rank', values='count')\n",
    "pivoted_counts.columns = [f'rank_{col}' for col in pivoted_counts.columns]\n",
    "pivoted_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE ranking without RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe for periodID > 5\n",
    "df_mape_filtered = pd.concat([xgb_df, rf_df, sarima_df, bayes_df], ignore_index=True)\n",
    "df_mape_filtered = df_mape_filtered[df_mape_filtered['model'] != 'rf']\n",
    "df_mape_filtered = df_mape_filtered.melt(id_vars=['periodID', 'model'], var_name='ATM', value_name=measure)\n",
    "df_mape_filtered['rank'] = df_mape_filtered.groupby(['periodID', 'ATM'])[measure].rank(method='min')\n",
    "# group and count the data\n",
    "counts = df_mape_filtered.groupby(['model', 'rank']).size().reset_index(name='count')\n",
    "\n",
    "# pivot the counts dataframe to a wider format\n",
    "pivoted_counts = counts.pivot(index='model', columns='rank', values='count')\n",
    "pivoted_counts.columns = [f'rank_{col}' for col in pivoted_counts.columns]\n",
    "pivoted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_df = sarima_raw_df.loc[sarima_raw_df['name'] == 'MAPE']\n",
    "nan_columns = mape_df.columns[mape_df.isna().any()].tolist()\n",
    "nan_ints = [int(col[-2:]) for col in nan_columns]\n",
    "print(nan_ints)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concatenate the three DataFrames\n",
    "combined_df = pd.concat([bayes_df, sarima_df, xgb_df], ignore_index=True)\n",
    "\n",
    "# Remove rows where periodID is 2 or 7\n",
    "df = combined_df[(combined_df['periodID'] != 2) & (combined_df['periodID'] != 7)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_raw_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankomaty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bd28fbdfb971f60e610ae214816a3c77bc93021cbbe5fbe921416ce4436b467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
